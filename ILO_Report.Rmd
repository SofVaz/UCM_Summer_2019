---
title: "The state of ILOs - Report"
knit: (function(input_file, encoding) {
  out_dir <- 'docs';
  rmarkdown::render(input_file,
 encoding=encoding,
 output_file=file.path(dirname(input_file), out_dir, 'index.html'))})
author: "Sofia Vazquez Alferez (DARS, University College Maastricht"
date: "08/07/2019"
output:
  html_document:
    toc: yes
    toc_float:
      collapsed: no
---


```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r libraries, include = F}
library(tidyverse)
library(stringr)
library(readxl)
library(tidytext)
library(udpipe) #language model
library(stargazer) #table output
```

```{r import, warning = F}
ilo_data <- read_excel("~/Documents/Summer UCM/ILO/ILO_2018_2019.xlsx", na = c("", "NA"))
```

```{r add course level and concentration label, warning = F}
ilo_data <- ilo_data %>% mutate(Level = str_sub(Course, start = 4, end = 4), Concentration = str_sub(Course, start = 1, end = 3))
```

```{r number of courses}
no_courses <- ilo_data %>% select(Course) %>% unique() %>% count() %>% pull(n)
no_ilo <- ilo_data %>% transmute(not_empty = !is.na(ILO)) %>% summarize(total_ilos = sum(not_empty)) %>% pull(total_ilos)
```
#Abstract
This document presents a brief overview of the current state of the *Intended Learning Objectives* (hereafter *ILO*). Including information on:

* The number of ILOs in our courses.

* The orientation of language used in ILOs

* The most common capacities the ILOs promote broken down by Level and Concentration

* [NOT DONE YET] A description of how the current objectives map to Bloom's Taxonomy of learning.

* [NOT DONE YET] Recommendations on how to write ILOs

* [NOT DONE YET] Suggested rephrasing of current ILO's

#A brief overview of our data
For this analysis I used the *ILOs* for the year *2018/2019* provided by Edith. The *ILOs* of the projects (PRO) were missing from this file, and have therefore not been included in the subsequent analysis. I did have the *ILOs* for the Undergraduate Research Projects (UGR), so these are inlcuded.  
The data contained a total of **`r no_courses`** **courses**, which amounted to **`r no_ilo`** **ILOs**.
All quotes from *ILOs* are referenced with base to the `ILOs_2018_2019.docx` document.

##How many of ILOs do our courses have? (distribution per course)
In general, the courses had an average of `r round(no_ilo/no_courses,1)` *ILOs* per course. Which were distributed as follows:

```{r distribution of ILOs per course, warning = FALSE}
ilo_data %>% 
  mutate(not_empty = !is.na(ILO)) %>% 
  group_by(Course) %>%
  summarise(Number_ilos = sum(not_empty)) %>%
  count(Number_ilos) %>% 
  ggplot(aes(x = Number_ilos, y = n)) +
  geom_histogram(stat = "identity", fill = "navy") +
  labs(title= "Distribution of ILOs per Course", x = "Number of ILOs", y = "Number of Courses (with said number of ILOs)") +
  theme_minimal()
```

A breakdown by Level and Concentration gives:  
[to be added]

##With what orientation are they written? (Student vs. Course)
It was possible to distinguish two categories in the way *ILOs* were formulated. *ILOs* were either as student (S) oriented or course (C) oriented.
**Student oriented** *ILOs* described what the student was supposed to achieve or have learned during the course, whilst **course oriented** *ILOs* described the aims of the course. For example:  

1. Student Oriented *ILO*:  

> “To offer a broad overview of scientific models” (COR1005, p. 1)  
  “To acquaint students with the problems…” (HUM2030, p.3)  
  “To enhance their research skills” (SKI1009, p.11)  
  
2. Course Oriented *ILO*:  

> “Apply basic bookkeeping techniques” (SSC2022, p.15)  
  “To reflect on the relevance and utility of social theory in general”(SSC2028, p.15)

A few courses had some *ILOs* formulated in a student oriented fashion and others *ILOs* in a course oriented fashion. Thus, overview bellow is done at a granularity of *ILO* not courses.

In general, this is what we have in the curriculum in raw numbers:

```{r course orientation, warning = FALSE}
ilo_data %>% select(`Course_Intention/Student_profile`) %>% group_by(`Course_Intention/Student_profile`) %>% count() %>%
  ggplot(aes(x = `Course_Intention/Student_profile`, y = n, label = n)) +
  geom_histogram(stat = "identity", fill = "navy")+
  geom_text(vjust = -0.5) +
  labs(title = "ILO formulation orientation", x = "Course (C) vs Student (S) Orientation", y = "Number of ILOs")+
  theme_classic()
  
```

In percentages, we have the following:

```{r orientation percentage, warning = FALSE}
ilo_data %>% select(`Course_Intention/Student_profile`) %>% group_by(`Course_Intention/Student_profile`) %>% count() %>%
  ungroup() %>%
  mutate(percentage = n*100/sum(n)) %>%
  ggplot(aes(x = `Course_Intention/Student_profile`, y = percentage, label = round(percentage))) +
  geom_histogram(stat = "identity", fill = "navy")+
  geom_text(vjust = -0.5) +
  labs(title = "ILO formulation orientation", x = "Course (C) vs Student (S) Orientation", y = "Percentage of ILOs [rounded]")+
  theme_classic()
  
```
###Inspecting NA orientation category
The `NA` category represents courses that I did not classify in any of those categories. They were the following *ILOs*:

```{r Orientation unclear, results = "asis"}
knitr::kable(
  x = ilo_data %>% 
    filter(is.na(`Course_Intention/Student_profile`)) %>% 
    select(Course, ILO), 
  
  caption = "Table of ILOs wihout orientation category"
  )
```

#Analysing our ILOs

##Methodology

###Phase 1- Verb extraction
In order to get a better grasp of the characterization of our *ILOs*, I manually went through all *ILOs* and extracted the verb(s) describing what the student was supposed to do in each *ILO*. This created a distiction between the course verb and the student verb, as well as between the `action verb` and the `intended verb`.  For instance:  

**1. Course verb/Student verb:**  
For the ILO "to provide students with [...] perspectives to examine..." (COR1004, p.1) the extracted verb is "[to] examine" not "[to] provide". 

**2. Action verb/Intended verb:** 
For the ILO "to have the ability to interpret dynamical phenomena..."(SCI3006, p. 9) the verb "[to] interpret" was extracted not "[to] have (the ability)".  

In cases where the verb used was missleading, descriptive words were included. For instance, in the ILO "Gain basic knowledge in using economic/statistical data and present them in an informative way" (SSC2038, p. 15), the words "Gain basic knowledge" were recorded, as opposed to simply "[to] gain". For this specific ILO, the verbs "use" and "present" were also extracted, as each ILO could have more than one verb associated to them. 

During this phase I tried to keep as close as possible to the original formulation, although as I advanced through the *ILOs* I started to adapt some of the formulations to create some consistency with previously encountered data. Thus, particularily at the end formulations such as "to perform an analysis" were simply extracted as "analyse". Moreover, because of this fidelity principle, some of the verbs for ilos were not verbs at all but conveyed the expected outcome. For instance, "overview" was extracted from the following ILO: "To give an overview over the different media platforms and media practices" (HUM2022, p.3), since the student was suppoded to 'get an overview'.

This phase was performed in Excel and all extracted verbs were recorded in the same row as the original formulation, so it is possible to trace back the work and contest my check my interpretations.

In the following list, it is possible to see all the verbs that were extracted:

```{r clean ilo data}
ilo_data_clean <- ilo_data %>% 
  mutate(Verb_used_1 = case_when(is.na(Verb_used_1)~"NaN",
                                            T~Verb_used_1))      %>%
  gather(key = tmp_place, value = Verb, Verb_used_1:Verd_used_3) %>% 
  select(-tmp_place) %>% 
  filter(!is.na(Verb)) %>% 
  mutate(Verb = map_chr(Verb, function(x) str_replace(x,"NaN",NA_character_)))
```

```{r dirty verbs}
dirty_verbs <- ilo_data_clean %>% pull(Verb) %>% unique()
```
```{r print dirty verbs, results = "asis"}
knitr::kable(
  x = tibble(Verbs = dirty_verbs), 
  
  caption = "Extracted verbs after Phase 1"
  )
```

###Phase 2- Standardisation  
As you can see, some verbs are really similar. For example, we have: "to understand", "understand" and "basic understanding". Therefore, in `Phase 2` I standardised some of the vocabulary. All of the previous words were replaced by the same words: "understand". Here is an overview of the replacements:

```{r collapse or}
collapse_or <- function(string_vector){
  paste(string_vector, collapse ="$|^")
}
```

```{r search for equivalence}
#UNDERSTAND
understand_eq <- ilo_data_clean %>% filter(str_detect(Verb, "understa")) %>% pull(Verb) %>% unique()
# print(paste('"understand":', paste(understand_eq, collapse = ", "), sep = " "))

#KNOW
know_eq <- ilo_data_clean %>% filter(str_detect(Verb, "know")) %>% pull(Verb) %>% unique()
# print(paste('"know":', paste(know_eq, collapse = ", "), sep = " ")) # "gain "basic practial knowledge" and "use knowledge" might not be correct here rather in "apply".

#[GAIN] FAMILIARITY
familiarise_eq <- ilo_data_clean %>% filter(str_detect(Verb, "familia")) %>% pull(Verb) %>% unique()
# print(paste('"[gain] familiarity":', paste(familiarise_eq, collapse = ", "), sep = " "))

#ANALYSE
analyse_eq <- ilo_data_clean %>% filter(str_detect(Verb, "analy")) %>% pull(Verb) %>% unique()
# print(paste('"analyse":', paste(analyse_eq, collapse = ", "), sep = " "))

#[BE] INTRODUCED
introduce_eq <- ilo_data_clean %>% filter(str_detect(Verb, "introd")) %>% pull(Verb) %>% unique()
# print(paste('"[be] introduced":', paste(introduce_eq, collapse = ", "), sep = " "))

#[GET] OVERVIEW
overview_eq <- ilo_data_clean %>% filter(str_detect(Verb, "overv")) %>% pull(Verb) %>% unique()
# print(paste('"[get] overview":', paste(overview_eq, collapse = ", "), sep = " "))

#[GET] ACQUAINTED
acquainted_eq <- ilo_data_clean %>% filter(str_detect(Verb, "acquain")) %>% pull(Verb) %>% unique()
# print(paste('"[get] acquainted":', paste(acquainted_eq, collapse = ", "), sep = " "))
```

```{r equivanlent classes}
#UNDERSTAND
understand_equivalence <- setdiff(understand_eq, c(""))
print(paste('The verbs that were taken to be the same as "understand" are:', paste(understand_equivalence, collapse = ", "), sep = " "))

#KNOW
know_equivalence <- setdiff(know_eq, c("use knowledge","gain basic practical knowledge"))
print(paste('The verbs that were taken to be the same as "know" are:', paste(know_equivalence, collapse = ", "), sep = " ")) # "gain "basic practial knowledge" and "use knowledge" might not be correct here rather in "apply".

#[GAIN] FAMILIARITY
familiarise_equivalence <- setdiff(familiarise_eq, c(""))
print(paste('The verbs that were taken to be the same as "[gain] familiarity" are:', paste(familiarise_equivalence, collapse = ", "), sep = " "))

#ANALYSE
analyse_equivalence <- setdiff(analyse_eq, c("to further (research, analyical and writing skills)", "define/analyse/answer", "reason analyticaly", "think analytically"))
print(paste('The verbs that were taken to be the same as "analyse" are:', paste(analyse_equivalence, collapse = ", "), sep = " "))

#[BE] INTRODUCED
introduce_equivalence <- setdiff(introduce_eq, c(""))
print(paste('The verbs that were taken to be the same as "[be] introduced" are:', paste(introduce_equivalence, collapse = ", "), sep = " "))

#[GET] OVERVIEW
overview_equivalence <- setdiff(overview_eq, c(""))
print(paste('The verbs that were taken to be the same as "[get] overview" are:', paste(overview_equivalence, collapse = ", "), sep = " "))

#[GET] ACQUAINTED
acquainted_equivalence <- setdiff(acquainted_eq, c(""))
print(paste('The verbs that were taken to be the same as "[get] acquainted" are:', paste(acquainted_equivalence, collapse = ", "), sep = " "))

```

```{r cleaning other verbs}
#Clean functions
remove_to <- function(string){
  str_replace(string, "to ", "")
}

#Standardize functions
standardize_knowing <- function(string){
  str_replace(string, collapse_or(know_equivalence), "know")
}

standardize_understand <- function(string){
  str_replace(string, collapse_or(understand_equivalence), "understand")
}

standardize_familiarity <- function(string){
  str_replace(string, collapse_or(familiarise_equivalence), "[gain] familiarity")
}

standardize_analyse <- function(string){
  str_replace(string, collapse_or(analyse_equivalence), "analyse")
}

standardize_introduce <- function(string){
  str_replace(string, collapse_or(introduce_equivalence), "[be] introduced")
}

standardize_overview <- function(string){
  str_replace(string, collapse_or(overview_equivalence), "[get] overview")
}

standardize_acquainted <- function(string){
  str_replace(string, collapse_or(acquainted_equivalence), "[get] acquainted")
}
```

```{r apply standarization}
ilo_data_clean <- ilo_data_clean %>% 
  mutate(
    Verb = map_chr(Verb, standardize_knowing),
    Verb = map_chr(Verb, standardize_understand),
    Verb = map_chr(Verb, standardize_familiarity),
    Verb = map_chr(Verb, standardize_analyse),
    Verb = map_chr(Verb, standardize_introduce),
    Verb = map_chr(Verb, standardize_overview),
    Verb = map_chr(Verb, standardize_acquainted),
    Verb = map_chr(Verb, function(string) str_replace(string, "to ", "")) #,
    #Verb = map_chr(Verb, function(string) str_replace(string, "^na$", NA_character_)) #this should not be necessary anymore.
  ) 
```

The result is a table like this:
```{r view clean ilos, results = "asis"}
knitr::kable(
  x = ilo_data_clean %>% select(Course, ILO, Verb) %>% arrange(Course, ILO)%>% head(13), 
  
  caption = "Table of ILOs with extravted standardized verb"
  )
```

##Results

###Rough numeric overview:

```{r summary statistics}
ilo_verb_stats_data <- ilo_data_clean %>%
  mutate(not_na_verb = 
           case_when(is.na(Verb) ~ 0, # makes NA verbs not count. 
             T ~1)) %>%
  group_by(Course, ILO) %>% 
  mutate(Verbs_per_ILO = sum(not_na_verb)) %>%
  ungroup() %>%
  select(Course, Level, Concentration, ILO, Verbs_per_ILO) %>%
  distinct() %>%
  group_by(Course) %>%
  mutate(ilo_per_course = n(),
         verbs_per_course = sum(Verbs_per_ILO)) %>%
  ungroup()

total_verb_objectives <- ilo_verb_stats_data %>%
  select(Course, verbs_per_course,ilo_per_course)  %>%
  distinct() %>%
  mutate(total_verbs = sum(verbs_per_course)) %>% 
  pull() %>%
  unique
```
After the previous methodology has been applied, we have `r total_verb_objectives` individual capacity learning objectives (hereafter capacities). These are the abilities we intend to promote in our students according to our learning objectives and correspond to individual "verbs" (e.g. "understand", "analyse"). The breakdown by level is as follows:

**Level 1000:** `r ilo_verb_stats_data %>% filter(Level == 1) %>% select(Course, verbs_per_course,ilo_per_course)  %>% distinct() %>% mutate(total_verbs = sum(verbs_per_course)) %>% pull() %>% unique()` capacities
```{r verbs at 1000}
# for other levels change Level filter
# ilo_verb_stats_data %>%
#   filter(Level == 1) %>%
#   select(Course, verbs_per_course,ilo_per_course)  %>%
#   distinct() %>%
#   mutate(total_verbs = sum(verbs_per_course)) %>% 
#   pull() %>%
#   unique() %>%
#   print
```
**Level 2000:** `r ilo_verb_stats_data %>% filter(Level == 2) %>% select(Course, verbs_per_course,ilo_per_course)  %>% distinct() %>% mutate(total_verbs = sum(verbs_per_course)) %>% pull() %>% unique()` capacities.

**Level 3000:** `r ilo_verb_stats_data %>% filter(Level == 1) %>% select(Course, verbs_per_course,ilo_per_course)  %>% distinct() %>% mutate(total_verbs = sum(verbs_per_course)) %>% pull() %>% unique()` capacities.

#####Graphically:

######Across all courses:

```{r distribution of verbs per course, warning = FALSE}
ilo_verb_stats_data %>%
  select(Course, Level, Concentration, verbs_per_course, ilo_per_course) %>%
  distinct() %>%
  #group_by(verbs_per_course) %>%
  count(verbs_per_course) %>%
  ggplot(aes(x = verbs_per_course, y = n)) +
  geom_histogram(stat = "identity", fill = "navy") +
  labs(title= "Number of Capacities promoted by Courses") +
  scale_x_continuous(name = "Number of Capacities",  breaks = seq(0,20,1))+
  scale_y_continuous("Number of Courses (promoting said number of Capacities)", breaks = seq(0,30,1))+
  theme_minimal()
```

######By  Level:

```{r graphs verbs level break down, warning = FALSE}

#Level 1000
ilo_verb_stats_data %>%
  filter(Level == 1) %>%
  select(Course, Level, Concentration, verbs_per_course, ilo_per_course) %>%
  distinct() %>%
  #group_by(verbs_per_course) %>%
  count(verbs_per_course) %>%
  ggplot(aes(x = verbs_per_course, y = n)) +
  geom_bar(stat = "identity", fill = "navy") +
  labs(title= "Number of Capacities promoted by 1000 Level Courses") +
  scale_x_continuous(name = "Number of Capacities",  breaks = seq(0,20,1))+
  scale_y_continuous("Number of Courses (promoting said number of Capacities)", breaks = seq(0,20,1))+
  theme_minimal()
  
#Level2000
ilo_verb_stats_data %>%
  filter(Level == 2) %>%
  select(Course, Level, Concentration, verbs_per_course, ilo_per_course) %>%
  distinct() %>%
  #group_by(verbs_per_course) %>%
  count(verbs_per_course) %>%
  ggplot(aes(x = verbs_per_course, y = n)) +
  geom_bar(stat = "identity", fill = "navy") +
  labs(title= "Number of Capacities promoted by 2000 Level Courses") +
  scale_x_continuous(name = "Number of Capacities",  breaks = seq(0,20,1))+
  scale_y_continuous("Number of Courses (promoting said number of Capacities)", breaks = seq(0,20,1))+
  theme_minimal()

#Level3000
ilo_verb_stats_data %>%
  filter(Level == 3) %>%
  select(Course, Level, Concentration, verbs_per_course, ilo_per_course) %>%
  distinct() %>%
  #group_by(verbs_per_course) %>%
  count(verbs_per_course) %>%
  ggplot(aes(x = verbs_per_course, y = n)) +
  geom_bar(stat = "identity", fill = "navy") +
  labs(title= "Number of Capacities promoted by 3000 Level Courses") +
  scale_x_continuous(name = "Number of Capacities",  breaks = seq(0,20,1))+
  scale_y_continuous("Number of Courses (promoting said number of Capacities)", breaks = seq(0,20,1))+
  theme_minimal()

```

###Capacities inspection
So what are these capacities?

####Across all courses
```{r verb counts maunal text analysis, warning = FALSE}
verbs_unrepeated <- ilo_data_clean %>%
  group_by(Verb)  %>%
  mutate(n = n()) %>%
  select(Verb, n) %>%
  distinct()      # %>%
  # filter(!is.na(Verb)) #REMOVE NA

verbs_unrepeated        %>%
  top_n(n = 20, wt = n) %>%
  arrange(desc(n))      %>%    
  ungroup()             %>%
  .[1:20,]              %>%
  ggplot(aes(x = reorder(Verb,-n), y = n)) +
  geom_histogram(stat = "identity", fill = "navy") +
  labs(title = "Most Common Capacities across all Courses", x = "Capacity", y = "Number of appearances") +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

####Breakdown by Level
```{r level break down manual text analysis, warning = FALSE}
levels <- 1:3
verbs_unrepeated <- ilo_data_clean %>%
  group_by(Level, Verb)            %>%
  mutate(n = n())                  %>%
  select(Level, Verb, n)           %>%
  distinct()

d_level_plots <- verbs_unrepeated %>% 
  group_by(Level)                 %>%
  top_n(n = 20, wt = n)           %>%
  ungroup()

for (lev in levels){
  plot <- d_level_plots %>%
    filter(Level == lev) %>%
    ggplot(aes(x = reorder(Verb,-n), y = n)) +
    geom_histogram(stat = "identity", fill = "navy") +
    labs(title = paste("Most Common Capacities for ", lev, "000 Level",sep = ""), x = "Capacity", y = "Number of appearances")+
    theme_classic() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  print(plot)
}
```

####Breakdown by Concentration
```{r concentration break down manual text analysis, warning = FALSE}
concentrations <- ilo_data_clean%>% select(Concentration) %>% distinct %>% pull

verbs_unrepeated <- ilo_data_clean %>%
  group_by(Concentration, Verb)            %>%
  mutate(n = n())                  %>%
  select(Concentration, Verb, n)           %>%
  distinct()

d_concentration_plots <- verbs_unrepeated %>% 
  group_by(Concentration)                 %>%
  top_n(n = 20, wt = n)           %>%
  ungroup()

for (conc in concentrations){
  plot <- d_concentration_plots %>%
    filter(Concentration == conc) %>%
    ggplot(aes(x = reorder(Verb,-n), y = n)) +
    geom_histogram(stat = "identity", fill = "navy") +
    labs(title = paste("Most Common Capacities for ", conc, sep = ""), x = "Capacity", y = "Number of appearances")+
    theme_classic() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  print(plot)
}
```

#Methods in ILO's
```{r}
no_ilo_methods <- ilo_data_clean %>% filter(`Methodology LO` == "M") %>% select(Course,ILO) %>% distinct %>% nrow()
```

A separate question to consider is: how many of our ILOs explicitly refer to methodology?
During the verb extraction, a comment was also made refering to whether or not the ILO explicitly refered to methodology. Out of the `r no_ilo` ILOs existing in the curricula, there were `r no_ilo_methods` about methodoloy (this is `r 100*no_ilo_methods/no_ilo`%).

Here are the ILO's which I marked as refering to methodology, the verbs used have been added for completeness:

```{r methodology ilos, results = "asis"}
paste_collapse <- function(vector){
  paste(vector, collapse = ", ")
}

methodology_ilos <- ilo_data_clean %>% 
  filter(`Methodology LO` == "M") %>% 
  select(Course, ILO, Verb) %>% 
  group_by(Course, ILO) %>%
  mutate(Verbs_used = paste_collapse(Verb)) %>% select(-Verb) %>% distinct() %>% arrange(Course)

knitr::kable(
  x = methodology_ilos, 
  
  caption = "ILOs concenrning to methodology"
  )
```

